<section class="bg-gray" id="program">

    <div class="container">

        <div class="row">
            <div class="col-lg-12 text-center">
                <h2 class="section-heading">PROGRAM</h2>
                <hr class="primary">
<!--                TBD-->
            </div>
        </div>
        <div class="row no-gutter">
            <table style="width: 100%">
                <tbody>
                    <tr style="border-bottom: 1px solid black; height: 30px">
                        <th class="th-1-Width" style="width:12%">Time (PST)</th>
                        <th class="th-1-Width" style="width:13%">Event</th>
                        <th class="th-1-Width" style="width:48%">Title</th>
                        <th class="th-1-Width" style="width:27%">Speaker(s)</th>
                    </tr>
                    <tr style="border-bottom: 1px solid black; height: 30px">
                        <td>08:30 - 08:45</td>
                        <td></td>
                        <td>Opening Remarks and Logistics for the Day</td>
                        <td><a class="page-scroll" href="#O1">Mei Chen, Microsoft</a></td>
                    </tr>
                    <tr style="border-bottom: 1px solid black; height: 30px">
                        <td>08:45 - 09:15</td>
                        <td>Invited Talk</td>
                        <td><b><a class="page-scroll" href="#talk_1">Leveraging AI Filters for Mitigating Viewer Impact from Disturbing Imagery</a></b></td>
                        <td>
                            <a class="page-scroll" href="#S6_info">Symeon Papadopoulos, ITI</a>
                        </td>
                    </tr>
                    <tr style="border-bottom: 1px solid black; height: 30px">
                        <td>09:15 - 09:45</td>
                        <td>Invited Talk</td>
                        <td><b><a class="page-scroll" href="#talk_2">Human Moderation in an Evolving Web Landscape: Wellness Gaps and Needs</a></b></td>
                        <td>
                            <a class="page-scroll" href="#S5_info">Marlyn Thomas Savio, TaskUs</a>
                        </td>
                    </tr>
                    <tr style="border-bottom: 1px solid black; height: 30px">
                        <td>09:45 - 10:15</td>
                        <td>Invited Talk</td>
                        <td><b><a class="page-scroll" href="#talk_3">Content Safeguarding in the Generative AI Era</a></b></td>
                        <td>
                            <a class="page-scroll" href="#S5_info">Paul Rad, UTSA</a>
                        </td>
                    </tr>
                    <tr style="border-bottom: 1px solid black; height: 30px">
                        <td>10:30 - 10:45</td>
                        <td>Coffee Break</td>
                        <td></td>
                        <td></td>
                    </tr>
                    <tr style="border-bottom: 1px solid black; height: 30px">
                        <td>10:30 - 11:20</td>
                        <td>Invited Talk</td>
                        <td><b><a class="page-scroll" href="#talk_4">Do moderators dream of AI support? Understanding what moderators really need through community-engaged research</a></b></td>
                        <td>
                            <a class="page-scroll" href="#S2_info">Sarah Gilbert, Cornell University</a>
                        </td>
                    </tr>
                    <tr style="border-bottom: 1px solid black; height: 30px">
                        <td>11:20 - 12:00</td>
                        <td>Panel Discussion</td>
                        <td><b>Culture, Context, Metrics, Transparency in Responsible AI</b></td>
                        <td>
                            <a class="page-scroll" href="#S2_info">Sarah Gilbert, Cornell University</a><br>
                            <a class="page-scroll" href="#S5_info">Paul Rad, UTSA</a><br>
                            <a class="page-scroll" href="#S6_info">Symeon Papadopoulos, ITI</a><br>
                            <a class="page-scroll" href="#S3_info">Xiang Hao, Amazon</a><br>
                        </td>
                    </tr>
                    <tr style="border-bottom: 1px solid black; height: 30px">
                        <td>12:00 - 13:30</td>
                        <td>Lunch Break</td>
                        <td>
                        </td>
                        <td>
                        </td>
                    </tr>
                    <tr style="border-bottom: 1px solid black; height: 30px">
                        <td>13:30 - 14:15</td>
                        <td>Invited Talk</td>
                        <td><b><a class="page-scroll" href="#talk_5">Ephemeral Chat Moderation: Understanding Invisible Harms</a></b></td>
                        <td>
                            <a class="page-scroll" href="#S1_info">Mike Pappas, Modulate AI</a>
                        </td>
                    </tr>
                    <tr style="border-bottom: 1px solid black; height: 30px">
                        <td>14:15 - 14:45</td>
                        <td>Invited Talk</td>
                        <td style="padding-right: 2px">
                            <b><a class="page-scroll" href="#talk_6">Enhancing Visual Content Safety: Multimodal Approaches for Dataset Curation and Model Safeguarding</a></b>
                        </td>
                        <td>
                            <a class="page-scroll" href="#S7_info">Manuel Black, TU Darmstadt</a>
                        </td>
                    </tr>
                    <tr style="border-bottom: 1px solid black; height: 30px">
                        <td>14:45 â€“ 15:15</td>
                        <td>Invited Talk</td>
                        <td style="padding-right: 2px">
                            <b><a class="page-scroll" href="#talk_7">Multimodal Deception Detection using Automatically Extracted Acoustic, Visual, and Lexical Features</a></b>
                        </td>
                        <td>
                            <a class="page-scroll" href="#S8_info">Lin Ai, Columbia University</a>
                        </td>
                    </tr>
                    <tr style="border-bottom: 1px solid black; height: 30px">
                        <td>15:15 - 15:45</td>
                        <td>Coffee Break</td>
                        <td> </td>
                        <td> </td>
                    </tr>
                    <tr style="border-bottom: 1px solid black; height: 30px">
                        <td>15:45 - 16:45</td>
                        <td>Invited Talk</td>
                        <td><b><a class="page-scroll" href="#talk_8">Fair and Inclusive Multimodal Generations</a></b></td>
                        <td>
                            <a class="page-scroll" href="#S4_info">Susanna Ricco, Google DeepMind</a>
                        </td>
                    </tr>
                    <tr style="border-bottom: 1px solid black; height: 30px">
                        <td>16:45 - 17:00</td>
                        <td>Accepted Paper</td>
                        <td><b><a class="page-scroll" href="#talk_9">An End-to-End Vision Transformer Approach for Image Copy Detection</a></b></td>
                        <td>Jiahe Steven Lee, Mong Li Lee, Wynne Hsu<br>National University of Singapore</td>
                    </tr>
                    <tr style="border-bottom: 1px solid black; height: 30px">
                        <td>17:00 - 17:40</td>
                        <td>Panel Discussion</td>
                        <td><b>Multimodal Generation,  Moderation, Evaluation</b></td>
                        <td>
                            <a class="page-scroll" href="#S4_info">Susanna Ricco, Google DeepMind</a><br>
                            <a class="page-scroll" href="#S1_info">Mike Pappas, Modulate AI</a><br>
                            <a class="page-scroll" href="#S7_info">Manuel Black, TU Darmstadt</a><br>
                            <a class="page-scroll" href="#S8_info">Kaustav Kundu, Amazon</a><br>
                        </td>
                    </tr>
                    <tr style="border-bottom: 1px solid black; height: 30px">
                        <td>17:40 - 17:35</td>
                        <td></td>
                        <td>Closing Remarks</td>
                        <td><a class="page-scroll" href="#O1">Mei Chen, Microsoft</a></td>
                    </tr>

                </tbody>
            </table>
        </div>
        <br>
        <br>
        <div id="talk_1" class="row no-gutter">
            <h4>Leveraging AI Filters for Mitigating Viewer Impact from Disturbing Imagery</h4>
            <div class="col-md-12" style="margin-bottom: 30px; text-align: justify">
                <b>Speakers: Symeon Papadopoulos, ITI</b><br><br>
                <b>Abstract:</b> TBD
            </div>
        </div>
        <div id="talk_2" class="row no-gutter">
            <h4>Human Moderation in an Evolving Web Landscape: Wellness Gaps and Needs</h4>
            <div class="col-md-12" style="margin-bottom: 30px; text-align: justify">
                <b>Speakers: Marlyn Thomas Savio, TaskUs</b><br><br>
                <b>Abstract:</b> TBD
            </div>
        </div>
        <div id="talk_3" class="row no-gutter">
            <h4>Content Safeguarding in the Generative AI Era</h4>
            <div class="col-md-12" style="margin-bottom: 30px; text-align: justify">
                <b>Speakers: Paul Rad, UTSA</b><br><br>
                <b>Abstract:</b> TBD
            </div>
        </div>
        <div id="talk_4" class="row no-gutter">
            <h4>Do moderators dream of AI support? Understanding what moderators really need through community-engaged research</h4>
            <div class="col-md-12" style="margin-bottom: 30px; text-align: justify">
                <b>Speakers: Sarah Gilbert, Cornell University</b><br><br>
                <b>Abstract:</b> TBD
            </div>
        </div>
        <div id="talk_5" class="row no-gutter">
            <h4>Ephemeral Chat Moderation: Understanding Invisible Harms</h4>
            <div class="col-md-12" style="margin-bottom: 30px; text-align: justify">
                <b>Speakers: Mike Pappas, Modulate AI</b><br><br>
                <b>Abstract:</b> TBD
            </div>
        </div>
        <div id="talk_6" class="row no-gutter">
            <h4>Enhancing Visual Content Safety: Multimodal Approaches for Dataset Curation and Model Safeguarding</h4>
            <div class="col-md-12" style="margin-bottom: 30px; text-align: justify">
                <b>Speakers: Manuel Black, TU Darmstadt</b><br><br>
                <b>Abstract:</b> TBD
            </div>
        </div>
        <div id="talk_7" class="row no-gutter">
            <h4>Multimodal Deception Detection using Automatically Extracted Acoustic, Visual, and Lexical Features</h4>
            <div class="col-md-12" style="margin-bottom: 30px; text-align: justify">
                <b>Speakers: Lin Ai, Columbia University</b><br><br>
                <b>Abstract:</b> Deception detection in conversational dialogue has attracted much attention in recent years. Existing methods rely heavily on human-labeled annotations, which are costly and potentially inaccurate. In this work, we present an automated system that utilizes multimodal features for conversational deception detection without human annotations. We study the predictive power of different modalities and combine them for better performance. We use openSMILE to extract acoustic features after applying noise reduction techniques to the original audio. Facial landmark features are extracted from the visual modality. We experiment with training facial expression detectors and applying Fisher Vectors to encode sequences of facial landmarks of varying lengths. Linguistic features are extracted from automatic transcriptions of the data. We examine the performance of these methods on the Box of Lies dataset of deception game videos, achieving 73% accuracy using features from all modalities. This result is significantly better than previous results on this corpus, which relied on manual annotations, and also better than human performance.
            </div>
        </div>
        <div id="talk_8" class="row no-gutter">
            <h4>Fair and Inclusive Multimodal Generations</h4>
            <div class="col-md-12" style="margin-bottom: 30px; text-align: justify">
                <b>Speakers: Suzanna Ricco, Google DeepMind</b><br><br>
                <b>Abstract:</b> TBD
            </div>
        </div>
        <div id="talk_9" class="row no-gutter">
            <h4>An End-to-End Vision Transformer Approach for Image Copy Detection</h4>
            <div class="col-md-12" style="margin-bottom: 30px; text-align: justify">
                <b>Speakers: Jiahe Steven Lee, Mong Li Lee, Wynne Hsu (National University of Singapore)</b><br><br>
                <b>Abstract:</b> TBD
            </div>
        </div>

    </div>
</section>
